# The data which is loaded to train
# The training data is versioned with DVC
external_data_config:
  external_data_csv: data/external/train.csv

# Here the configurations of the raw data are set
# Specifically it is shown, how the training data is handled (e.g. how the data is split for training)
raw_data_config: 
  raw_data_csv: data/raw/train.csv
  model_var: ['churn','number_vmail_messages','total_day_calls','total_eve_minutes','total_eve_charge','total_intl_minutes','number_customer_service_calls']
  train_test_split_ratio: 0.2
  target: churn 
  random_state: 111
  new_train_data_csv: data/raw/train_new.csv

# How is the data further processed
# The data is already split into training and test set
processed_data_config:
  train_data_csv: data/processed/churn_train.csv
  test_data_csv:  data/processed/churn_test.csv

# Configs, which are necessary for mlflow to run
# The model which is going to be used, is a random forest
mlflow_config:
  artifacts_dir: artifacts
  experiment_name: model_iteration_larsfoehr
  run_name: random_forest
  registered_model_name: random_forest_model
  remote_server_uri: http://localhost:123
 
 # Specficifations of the random forest model
random_forest: 
  max_depth: 10
  n_estimators: 30

# Folder in which the model is saved
model_dir: models/model.joblib

# Folder from which our flask application gets the model
model_webapp_dir: webapp/model_webapp_dir/model.joblib

# Configs for model monitoring: Which is the target variable and where is the monitoring shown?
model_monitor:
  target_col_name: target
  monitor_dashboard_html: reports/data_and_target_drift_dashboard.html